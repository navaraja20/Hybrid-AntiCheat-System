# Hybrid Anti-Cheat System
### A Hybrid ML/DL Approach for Game Integrity

[![Python](https://img.shields.io/badge/Python-3.9+-blue.svg)](https://www.python.org/)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.100+-green.svg)](https://fastapi.tiangolo.com/)
[![License](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)

---

## ğŸ¯ Project Overview

This is a **production-ready anti-cheat system** that demonstrates how modern game integrity systems work. Unlike naive ML-only approaches, this project implements a **realistic hybrid architecture** combining deterministic rules, anomaly detection, supervised learning, and human review.

### Why This Project Matters

Most anti-cheat portfolio projects make the mistake of relying solely on ML/DL, which is unrealistic and vulnerable. This project mirrors real-world systems used by companies like Riot Games (Vanguard), Valve (VAC), and Easy Anti-Cheat by:

- **Never trusting the client** - Server-side validation first
- **Combining multiple detection layers** - No single point of failure
- **Focusing on explainability** - Bans need justification
- **Building for adversarial environments** - Cheaters will try to evade
- **Prioritizing precision over recall** - False positives destroy player trust

---

## ğŸ—ï¸ Architecture Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Game Client (Simulated)                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚  â”‚ Legit    â”‚  â”‚ Aimbot   â”‚  â”‚ Wallhack â”‚  â”‚ Triggerbotâ”‚       â”‚
â”‚  â”‚ Players  â”‚  â”‚ (smooth) â”‚  â”‚ (ESP)    â”‚  â”‚ (jitter) â”‚       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Telemetry Collector (FastAPI)                       â”‚
â”‚  â€¢ Ingests player actions (aim, movement, clicks)                â”‚
â”‚  â€¢ Rate limiting & validation                                    â”‚
â”‚  â€¢ Streams to message queue                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   Kafka / Redis Stream                           â”‚
â”‚  â€¢ Decouples ingestion from processing                           â”‚
â”‚  â€¢ Enables replay for model training                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           Feature Engineering Service                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚
â”‚  â”‚ Per-Frame Features:                                 â”‚         â”‚
â”‚  â”‚  â€¢ Jerk (3rd derivative) - detects aimbot snaps     â”‚         â”‚
â”‚  â”‚  â€¢ Click interval distribution - triggerbot         â”‚         â”‚
â”‚  â”‚  â€¢ Path entropy - wallhack navigation               â”‚         â”‚
â”‚  â”‚  â€¢ Headshot rate - statistical impossibility        â”‚         â”‚
â”‚  â”‚  â€¢ Recoil compensation - macro detection            â”‚         â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤         â”‚
â”‚  â”‚ Temporal Features (Sliding Windows):                â”‚         â”‚
â”‚  â”‚  â€¢ 30s / 5min / session aggregations                â”‚         â”‚
â”‚  â”‚  â€¢ Sequence patterns (LSTM/Transformer ready)       â”‚         â”‚
â”‚  â”‚  â€¢ Cheat toggle detection                           â”‚         â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  Detection Pipeline                              â”‚
â”‚                                                                   â”‚
â”‚  1. Rule-Based Detection (Deterministic)                         â”‚
â”‚     â”œâ”€ Geometry checks (aim through walls)                       â”‚
â”‚     â”œâ”€ Timing analysis (superhuman reactions)                    â”‚
â”‚     â””â”€ Statistical impossibilities (100% headshot)               â”‚
â”‚                                                                   â”‚
â”‚  2. Anomaly Detection (Unsupervised ML)                          â”‚
â”‚     â”œâ”€ Isolation Forest on feature space                         â”‚
â”‚     â”œâ”€ Autoencoder reconstruction error                          â”‚
â”‚     â””â”€ Anomaly score > 3 std devs = flag                         â”‚
â”‚                                                                   â”‚
â”‚  3. Supervised Classification (Labeled Data)                     â”‚
â”‚     â”œâ”€ XGBoost / Random Forest                                   â”‚
â”‚     â”œâ”€ Trained on pseudo-labels from high-confidence anomalies   â”‚
â”‚     â””â”€ Confidence calibration (Platt scaling)                    â”‚
â”‚                                                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Decision Engine (Multi-Threshold)                   â”‚
â”‚                                                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚
â”‚  â”‚ Cross-Feature Validation:                           â”‚         â”‚
â”‚  â”‚  â€¢ Aim anomaly + Movement anomaly = â†‘ confidence    â”‚         â”‚
â”‚  â”‚  â€¢ Temporal consistency (sustained vs spike)        â”‚         â”‚
â”‚  â”‚  â€¢ Session-level aggregation                        â”‚         â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚
â”‚                                                                   â”‚
â”‚  Decision Tree:                                                   â”‚
â”‚  â”œâ”€ Score > 0.95 â†’ Immediate Ban                                 â”‚
â”‚  â”œâ”€ Score 0.85-0.95 â†’ Shadow Ban (24h observation)               â”‚
â”‚  â”œâ”€ Score 0.70-0.85 â†’ Review Queue (human moderator)             â”‚
â”‚  â””â”€ Score < 0.70 â†’ Monitor                                       â”‚
â”‚                                                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Review Queue & Feedback Loop                  â”‚
â”‚                                                                   â”‚
â”‚  Human Reviewer Interface:                                       â”‚
â”‚  â”œâ”€ View flagged sessions with feature visualizations            â”‚
â”‚  â”œâ”€ Approve/Reject decisions                                     â”‚
â”‚  â””â”€ Feedback â†’ Retraining pipeline                               â”‚
â”‚                                                                   â”‚
â”‚  Ban Appeal System:                                              â”‚
â”‚  â””â”€ Ground truth labels for model improvement                    â”‚
â”‚                                                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚             PostgreSQL + Time-Series DB (InfluxDB)               â”‚
â”‚  â€¢ Player telemetry history                                      â”‚
â”‚  â€¢ Detection events & verdicts                                   â”‚
â”‚  â€¢ Model predictions & confidence scores                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 Monitoring & Observability                       â”‚
â”‚                                                                   â”‚
â”‚  Grafana Dashboards:                                             â”‚
â”‚  â”œâ”€ Detection rate over time                                     â”‚
â”‚  â”œâ”€ False positive rate (from appeals)                           â”‚
â”‚  â”œâ”€ Time-to-detection distribution                               â”‚
â”‚  â””â”€ Feature drift monitoring                                     â”‚
â”‚                                                                   â”‚
â”‚  Alerts:                                                          â”‚
â”‚  â”œâ”€ Model performance degradation                                â”‚
â”‚  â”œâ”€ New cheat pattern clusters                                   â”‚
â”‚  â””â”€ System latency spikes                                        â”‚
â”‚                                                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ§  Why This Approach Works

### The Problem with ML-Only Anti-Cheat

âŒ **Adversarial Vulnerability**: Cheaters can reverse-engineer and fool ML models  
âŒ **Data Scarcity**: Labeled cheat data is rare, especially for new exploits  
âŒ **False Positives**: Black-box models can ban innocents without explanation  
âŒ **Constant Retraining**: Models decay as cheat techniques evolve  

### Our Hybrid Solution

âœ… **Defense in Depth**: Multiple detection layers (rule â†’ anomaly â†’ supervised â†’ human)  
âœ… **Explainability**: Every ban has traceable evidence (not just "the model said so")  
âœ… **Adversarial Robustness**: Physics-based features are hard to fake  
âœ… **Feedback Loop**: Human reviews improve model over time  

---

## ğŸ”¬ Feature Engineering Deep Dive

Our features are designed around **what makes cheats detectable**, not just "feed everything to a neural network."

### 1. **Jerk (3rd Derivative of Position)**
```python
# Why it works:
# - Human aim: Smooth acceleration/deceleration
# - Aimbot: Discontinuous snap â†’ infinite jerk spike
# - Physics: dÂ³position/dtÂ³ should be bounded for humans
```
**Detection**: Aimbots often have jerk > 1000 units/sÂ³, while humans peak at ~200

### 2. **Click Interval Distribution**
```python
# Why it works:
# - Humans: Variable timing (Î¼=150ms, Ïƒ=50ms)
# - Triggerbot: Suspiciously consistent (Ïƒ < 10ms)
# - Detection: Measure coefficient of variation (CV = Ïƒ/Î¼)
```
**Detection**: CV < 0.1 = bot, CV > 0.2 = human

### 3. **Path Entropy**
```python
# Why it works:
# - Wallhackers navigate "too efficiently" (straight to enemies)
# - Legit players: Random exploration, backtracking
# - Measure: Shannon entropy of movement directions
```
**Detection**: Entropy < 2.5 bits = suspicious, > 4.0 bits = normal

### 4. **Headshot Rate with Reaction Time**
```python
# Why it works:
# - 80% headshot rate is possible for pros... but not with 50ms reaction time
# - Cross-validate: High HS% + Low reaction time = cheat
```

### 5. **Recoil Compensation Consistency**
```python
# Why it works:
# - Humans: Imperfect recoil control (variance in compensation)
# - Macro: Perfect pattern every time
# - Measure: Variance of recoil vector over shots
```

### Temporal Features (Sliding Windows)
- **30-second window**: Detect "rage mode" toggling
- **5-minute session**: Baseline player skill level
- **Full match**: Session-level anomaly scoring

---

## ğŸ® Simulated Cheat Behaviors (Threat Model)

To train and test the system, we simulate **realistic cheats** (not naive implementations):

### 1. **Smooth Aimbot**
```python
# Not just instant snap! Simulate modern cheats:
- Reaction delay (100-200ms) to look human
- Smoothing factor (gradual approach to target)
- Occasional "misses" (98% accuracy, not 100%)
- FOV limit (only lock within 45Â° cone)
```

### 2. **Triggerbot with Jitter**
```python
# Not constant timing! Add realism:
- Base delay + Gaussian noise (Î¼=120ms, Ïƒ=15ms)
- Simulate input lag variance
- Occasional "choke" (missed shots)
```

### 3. **Wallhack (ESP)**
```python
# Behavioral signature:
- Lower path entropy (optimal routing)
- Pre-aim at corners (aim at wall before enemy visible)
- No "surprise" reactions (always ready)
```

### 4. **Speedhack**
```python
# Geometry-based detection:
- Movement speed > max allowed speed
- Impossible position deltas (teleportation)
```

---

## ğŸ“Š Success Metrics

### Primary Metrics
1. **Precision** (minimize false positives): Target > 99.5%
2. **Time-to-Detection**: < 5 minutes for obvious cheats
3. **Evasion Resistance**: Can you fool your own system?

### Secondary Metrics
- Recall (catch rate): Target > 85%
- Review queue efficiency: < 5% need human review
- Appeal rate: < 0.1% of bans

### Evaluation Strategy
- **Baseline Comparison**: Pure rules vs pure ML vs hybrid
- **Adversarial Testing**: Red team attacks on your own system
- **Ablation Study**: Which features matter most?

---

## ğŸ› ï¸ Tech Stack

### Core Services
- **Python 3.9+**: Main language
- **FastAPI**: Telemetry ingestion API
- **Kafka / Redis**: Event streaming
- **PostgreSQL**: Relational data (bans, appeals)
- **InfluxDB**: Time-series telemetry

### ML/Data Science
- **scikit-learn**: Isolation Forest, preprocessing
- **XGBoost**: Supervised classification
- **PyTorch**: Autoencoder, future LSTM/Transformer
- **pandas**: Feature engineering
- **numpy**: Numerical computation

### Infrastructure
- **Docker**: Containerization
- **Docker Compose**: Multi-service orchestration
- **Grafana**: Dashboards
- **Prometheus**: Metrics collection
- **Nginx**: API gateway (optional)

### Development
- **pytest**: Testing
- **black**: Code formatting
- **mypy**: Type checking
- **pre-commit**: Git hooks

---

## ğŸš€ Quick Start

### Prerequisites

Before you begin, ensure you have:
- **Python 3.9 or higher** ([Download](https://www.python.org/downloads/))
- **Docker Desktop** ([Download](https://www.docker.com/products/docker-desktop))
- **Git** ([Download](https://git-scm.com/downloads))
- **8GB RAM minimum** (for Kafka + services)
- **10GB free disk space**

### Installation Steps

#### 1. Clone the Repository
```bash
git clone https://github.com/yourusername/anti-cheat-system.git
cd anti-cheat-system
```

#### 2. Set Up Python Environment
```bash
# Create virtual environment
python -m venv venv

# Activate (Windows)
venv\Scripts\activate

# Activate (Linux/Mac)
source venv/bin/activate

# Install dependencies
pip install -r requirements.txt
```

#### 3. Start Infrastructure with Docker
```bash
# Start Kafka, Redis, PostgreSQL, InfluxDB, Grafana
docker-compose up -d

# Verify services are running
docker-compose ps
```

#### 4. Initialize Database
```bash
# Run migrations
python scripts/init_db.py

# Load sample data (optional)
python scripts/load_sample_data.py
```

#### 5. Run the System
```bash
# Terminal 1: Start telemetry collector
python src/api/collector.py

# Terminal 2: Start feature engineering service
python src/processing/feature_service.py

# Terminal 3: Start detection pipeline
python src/detection/pipeline.py

# Terminal 4: Start game simulator
python src/simulation/game_client.py
```

#### 6. Access Dashboards
- **API Docs**: http://localhost:8000/docs
- **Grafana**: http://localhost:3000 (admin/admin)
- **Review Queue**: http://localhost:8000/review

---

## ğŸ“ Project Structure

```
anti-cheat-system/
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ collector.py          # FastAPI telemetry ingestion
â”‚   â”‚   â”œâ”€â”€ routes/
â”‚   â”‚   â”‚   â”œâ”€â”€ telemetry.py      # POST /telemetry endpoint
â”‚   â”‚   â”‚   â””â”€â”€ review.py         # Review queue API
â”‚   â”‚   â””â”€â”€ models.py             # Pydantic schemas
â”‚   â”‚
â”‚   â”œâ”€â”€ simulation/
â”‚   â”‚   â”œâ”€â”€ game_client.py        # Simulated game client
â”‚   â”‚   â”œâ”€â”€ players/
â”‚   â”‚   â”‚   â”œâ”€â”€ legit_player.py   # Normal behavior
â”‚   â”‚   â”‚   â”œâ”€â”€ aimbot_player.py  # Smooth aimbot simulation
â”‚   â”‚   â”‚   â”œâ”€â”€ wallhack_player.py
â”‚   â”‚   â”‚   â””â”€â”€ triggerbot_player.py
â”‚   â”‚   â””â”€â”€ environment.py        # Game physics
â”‚   â”‚
â”‚   â”œâ”€â”€ processing/
â”‚   â”‚   â”œâ”€â”€ feature_service.py    # Kafka consumer â†’ feature extraction
â”‚   â”‚   â”œâ”€â”€ features/
â”‚   â”‚   â”‚   â”œâ”€â”€ jerk.py           # 3rd derivative calculation
â”‚   â”‚   â”‚   â”œâ”€â”€ entropy.py        # Path entropy
â”‚   â”‚   â”‚   â”œâ”€â”€ click_analysis.py # Click interval distribution
â”‚   â”‚   â”‚   â””â”€â”€ temporal.py       # Sliding window aggregations
â”‚   â”‚   â””â”€â”€ streaming.py          # Kafka/Redis helpers
â”‚   â”‚
â”‚   â”œâ”€â”€ detection/
â”‚   â”‚   â”œâ”€â”€ pipeline.py           # Main detection orchestrator
â”‚   â”‚   â”œâ”€â”€ rules.py              # Deterministic checks
â”‚   â”‚   â”œâ”€â”€ anomaly.py            # Isolation Forest + Autoencoder
â”‚   â”‚   â”œâ”€â”€ supervised.py         # XGBoost classifier
â”‚   â”‚   â”œâ”€â”€ decision_engine.py   # Multi-threshold scoring
â”‚   â”‚   â””â”€â”€ models/               # Trained model artifacts
â”‚   â”‚
â”‚   â”œâ”€â”€ review/
â”‚   â”‚   â”œâ”€â”€ queue.py              # Human review interface
â”‚   â”‚   â”œâ”€â”€ feedback_loop.py      # Appeal processing â†’ retraining
â”‚   â”‚   â””â”€â”€ visualizations.py     # Feature charts for reviewers
â”‚   â”‚
â”‚   â”œâ”€â”€ training/
â”‚   â”‚   â”œâ”€â”€ train_anomaly.py      # Train Isolation Forest
â”‚   â”‚   â”œâ”€â”€ train_supervised.py   # Train XGBoost
â”‚   â”‚   â”œâ”€â”€ pseudo_labeling.py    # High-confidence anomalies â†’ labels
â”‚   â”‚   â””â”€â”€ evaluation.py         # Metrics, ablation studies
â”‚   â”‚
â”‚   â”œâ”€â”€ database/
â”‚   â”‚   â”œâ”€â”€ models.py             # SQLAlchemy ORM models
â”‚   â”‚   â”œâ”€â”€ postgres.py           # PostgreSQL connection
â”‚   â”‚   â””â”€â”€ influx.py             # InfluxDB time-series
â”‚   â”‚
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ config.py             # Configuration management
â”‚       â”œâ”€â”€ logging.py            # Structured logging
â”‚       â””â”€â”€ metrics.py            # Prometheus metrics
â”‚
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ unit/
â”‚   â”‚   â”œâ”€â”€ test_features.py
â”‚   â”‚   â”œâ”€â”€ test_rules.py
â”‚   â”‚   â””â”€â”€ test_models.py
â”‚   â”œâ”€â”€ integration/
â”‚   â”‚   â”œâ”€â”€ test_pipeline.py
â”‚   â”‚   â””â”€â”€ test_api.py
â”‚   â””â”€â”€ adversarial/
â”‚       â”œâ”€â”€ test_evasion.py       # Red team tests
â”‚       â””â”€â”€ cheat_variants.py     # Novel cheat simulations
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ init_db.py                # Database initialization
â”‚   â”œâ”€â”€ train_models.py           # One-command training
â”‚   â”œâ”€â”€ benchmark.py              # Performance testing
â”‚   â””â”€â”€ generate_report.py        # Evaluation report
â”‚
â”œâ”€â”€ configs/
â”‚   â”œâ”€â”€ development.yaml
â”‚   â”œâ”€â”€ production.yaml
â”‚   â””â”€â”€ feature_config.yaml       # Feature engineering parameters
â”‚
â”œâ”€â”€ docker/
â”‚   â”œâ”€â”€ Dockerfile.api
â”‚   â”œâ”€â”€ Dockerfile.processor
â”‚   â””â”€â”€ Dockerfile.detector
â”‚
â”œâ”€â”€ grafana/
â”‚   â””â”€â”€ dashboards/
â”‚       â”œâ”€â”€ detection_overview.json
â”‚       â”œâ”€â”€ feature_monitoring.json
â”‚       â””â”€â”€ model_performance.json
â”‚
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_exploratory_analysis.ipynb
â”‚   â”œâ”€â”€ 02_feature_engineering.ipynb
â”‚   â”œâ”€â”€ 03_model_training.ipynb
â”‚   â””â”€â”€ 04_evaluation.ipynb
â”‚
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ requirements-dev.txt
â”œâ”€â”€ .env.example
â”œâ”€â”€ .gitignore
â”œâ”€â”€ pytest.ini
â”œâ”€â”€ pyproject.toml
â””â”€â”€ README.md
```

---

## ğŸ”§ Configuration

### Environment Variables

Create a `.env` file:

```env
# Database
POSTGRES_HOST=localhost
POSTGRES_PORT=5432
POSTGRES_DB=anticheat
POSTGRES_USER=admin
POSTGRES_PASSWORD=changeme

# Kafka
KAFKA_BOOTSTRAP_SERVERS=localhost:9092
KAFKA_TOPIC_TELEMETRY=game.telemetry

# Redis
REDIS_HOST=localhost
REDIS_PORT=6379

# InfluxDB
INFLUXDB_URL=http://localhost:8086
INFLUXDB_TOKEN=your-token-here
INFLUXDB_ORG=anticheat
INFLUXDB_BUCKET=telemetry

# API
API_HOST=0.0.0.0
API_PORT=8000
API_WORKERS=4

# Detection Thresholds
THRESHOLD_IMMEDIATE_BAN=0.95
THRESHOLD_SHADOW_BAN=0.85
THRESHOLD_REVIEW_QUEUE=0.70

# Model Paths
MODEL_PATH_ISOLATION_FOREST=models/isolation_forest.pkl
MODEL_PATH_XGBOOST=models/xgboost.pkl
MODEL_PATH_AUTOENCODER=models/autoencoder.pth

# Feature Engineering
WINDOW_SIZE_SHORT=30  # seconds
WINDOW_SIZE_MEDIUM=300  # seconds
JERK_THRESHOLD=1000  # units/sÂ³
ENTROPY_THRESHOLD=2.5  # bits
CLICK_CV_THRESHOLD=0.1
```

### Feature Engineering Parameters

Edit `configs/feature_config.yaml`:

```yaml
features:
  jerk:
    enabled: true
    threshold: 1000
    window_size: 10  # frames
    
  click_interval:
    enabled: true
    cv_threshold: 0.1
    min_samples: 20
    
  path_entropy:
    enabled: true
    entropy_threshold: 2.5
    bin_size: 45  # degrees
    
  headshot_rate:
    enabled: true
    rate_threshold: 0.8
    reaction_time_threshold: 0.1  # seconds
    
  recoil_compensation:
    enabled: true
    variance_threshold: 0.05

temporal:
  windows:
    - 30    # seconds
    - 300   # 5 minutes
    - 1800  # 30 minutes
```

---

## ğŸ§ª Testing

### Run All Tests
```bash
pytest tests/ -v
```

### Unit Tests (Feature Engineering)
```bash
pytest tests/unit/test_features.py -v
```

### Integration Tests (Full Pipeline)
```bash
pytest tests/integration/test_pipeline.py -v
```

### Adversarial Tests (Red Team)
```bash
pytest tests/adversarial/test_evasion.py -v
```

### Generate Coverage Report
```bash
pytest --cov=src --cov-report=html
# Open htmlcov/index.html
```

---

## ğŸ“ˆ Training Models

### Step 1: Generate Synthetic Data
```bash
# Run game simulation to collect telemetry
python src/simulation/game_client.py --players 100 --duration 3600
# Generates data/telemetry/session_YYYYMMDD.parquet
```

### Step 2: Train Anomaly Detection
```bash
# Train Isolation Forest (unsupervised)
python src/training/train_anomaly.py \
  --data data/telemetry/ \
  --output models/isolation_forest.pkl

# Train Autoencoder (reconstruction error)
python src/training/train_autoencoder.py \
  --data data/telemetry/ \
  --output models/autoencoder.pth \
  --epochs 50
```

### Step 3: Generate Pseudo-Labels
```bash
# Use high-confidence anomalies as training labels
python src/training/pseudo_labeling.py \
  --anomaly-model models/isolation_forest.pkl \
  --threshold 0.95 \
  --output data/pseudo_labels.csv
```

### Step 4: Train Supervised Model
```bash
# Train XGBoost on pseudo-labels + human-reviewed data
python src/training/train_supervised.py \
  --data data/pseudo_labels.csv \
  --output models/xgboost.pkl \
  --calibrate  # Platt scaling for confidence
```

### Step 5: Evaluate
```bash
# Run comprehensive evaluation
python scripts/generate_report.py \
  --test-data data/test_set.parquet \
  --output reports/evaluation_YYYYMMDD.html
```

---

## ğŸ¯ Usage Examples

### Send Telemetry via API
```python
import requests

telemetry = {
    "player_id": "player_12345",
    "timestamp": 1643673600,
    "position": {"x": 100.5, "y": 200.3, "z": 50.0},
    "aim_direction": {"yaw": 45.0, "pitch": -10.0},
    "action": "fire",
    "target_hit": True,
    "headshot": True
}

response = requests.post(
    "http://localhost:8000/telemetry",
    json=telemetry
)
print(response.json())
# {'status': 'accepted', 'player_status': 'clean'}
```

### Query Detection Results
```python
# Get player's cheat score
response = requests.get(
    "http://localhost:8000/player/player_12345/score"
)
print(response.json())
# {
#   'player_id': 'player_12345',
#   'cheat_score': 0.23,
#   'status': 'clean',
#   'last_updated': '2026-02-01T12:00:00Z'
# }
```

### Review Queue
```python
# Get next case for human review
response = requests.get(
    "http://localhost:8000/review/next"
)
case = response.json()

# Submit verdict
requests.post(
    f"http://localhost:8000/review/{case['id']}/verdict",
    json={"verdict": "ban", "reason": "Obvious aimbot"}
)
```

---

## ğŸ“Š Monitoring

### Grafana Dashboards

Access http://localhost:3000 and import dashboards from `grafana/dashboards/`:

1. **Detection Overview**
   - Detection rate over time
   - Ban reasons distribution
   - Appeal success rate
   - System latency

2. **Feature Monitoring**
   - Feature distributions (detect drift)
   - Anomaly score trends
   - Cross-correlation matrix

3. **Model Performance**
   - Precision/Recall curves
   - ROC-AUC over time
   - Confidence calibration plots
   - False positive rate

### Alerts

Key alerts configured in Grafana:

- âš ï¸ **Model Degradation**: Precision drops below 99%
- ğŸš¨ **New Cheat Cluster**: Sudden spike in anomaly scores
- â±ï¸ **Latency Spike**: p99 latency > 500ms
- ğŸ“‰ **Data Pipeline Failure**: No telemetry for 5 minutes

---

## ğŸ›¡ï¸ Ethics & Privacy

### Principles

1. **Transparency**: Players know anti-cheat is active
2. **Explainability**: Every ban has evidence (not just "AI decided")
3. **Appeal Process**: Humans review contested cases
4. **Data Minimization**: Only collect necessary telemetry
5. **Retention Limits**: Telemetry deleted after 30 days (except ban evidence)

### Privacy Safeguards

- **No PII in telemetry**: Only anonymized player IDs
- **Encryption at rest**: PostgreSQL encrypted
- **Encryption in transit**: TLS for all API calls
- **Access control**: Role-based permissions for review queue

### Handling False Positives

```python
# Appeal workflow:
1. Player submits appeal via game client
2. Case added to priority review queue
3. Human reviewer examines:
   - Full session telemetry
   - Feature visualizations
   - Video replay (if available)
4. If false positive:
   - Ban lifted immediately
   - Compensation (in-game currency)
   - Case marked for model retraining
```

---

## ğŸ”¬ Advanced Topics

### Temporal Modeling with LSTMs

For detecting "cheat toggle" patterns:

```python
# Future enhancement (already architected for)
from src.detection.temporal import LSTMDetector

detector = LSTMDetector(
    sequence_length=100,  # 100 frames
    hidden_size=64
)

# Train on sequences of features
detector.fit(sequences, labels)

# Detect toggling (cheat on â†’ off â†’ on)
score = detector.predict(new_sequence)
```

### Adversarial Robustness Testing

Red team scripts in `tests/adversarial/`:

```python
# Test: Can you evade by adding noise?
python tests/adversarial/test_evasion.py --strategy noise

# Test: Can you evade by rate-limiting cheats?
python tests/adversarial/test_evasion.py --strategy sparse

# Test: Can you evade by mimicking human variance?
python tests/adversarial/test_evasion.py --strategy mimicry
```

Document results in `reports/adversarial_analysis.md`

### A/B Testing New Models

```python
# Gradual rollout strategy
# 1. Deploy new model in shadow mode (log predictions, don't act)
# 2. Compare with production model on same data
# 3. If metrics improve, route 10% traffic â†’ 50% â†’ 100%

from src.deployment.ab_test import ABTestManager

ab_test = ABTestManager()
ab_test.add_variant("control", model_v1, traffic_split=0.5)
ab_test.add_variant("treatment", model_v2, traffic_split=0.5)
ab_test.run(duration_hours=72)
ab_test.analyze()  # Chi-square test for significance
```

---

## ğŸš€ Production Deployment

### Scaling Considerations

1. **Horizontal Scaling**
   ```bash
   # Scale feature service
   docker-compose up -d --scale feature-service=5
   
   # Scale detection service
   docker-compose up -d --scale detector=3
   ```

2. **Kubernetes (Optional)**
   ```bash
   kubectl apply -f k8s/deployment.yaml
   kubectl autoscale deployment detector --cpu-percent=70 --min=3 --max=10
   ```

3. **Database Optimization**
   - Partition PostgreSQL by date (monthly)
   - InfluxDB retention policy (auto-delete after 30 days)
   - Redis LRU eviction for feature cache

### Performance Benchmarks

| Component           | Throughput   | Latency (p99) | Resource Usage |
|---------------------|--------------|---------------|----------------|
| Telemetry API       | 50K req/s    | 15ms          | 1 CPU, 512MB   |
| Feature Engineering | 20K events/s | 50ms          | 2 CPU, 2GB     |
| Detection Pipeline  | 10K evals/s  | 100ms         | 4 CPU, 4GB     |

---

## ğŸ¤ Contributing

This is a portfolio project, but contributions are welcome!

### Development Workflow

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/awesome-feature`)
3. Make your changes
4. Run tests (`pytest`)
5. Format code (`black src/`)
6. Type check (`mypy src/`)
7. Commit (`git commit -m 'Add awesome feature'`)
8. Push (`git push origin feature/awesome-feature`)
9. Open a Pull Request

### Code Style

- **Formatting**: Black (line length 100)
- **Type Hints**: Required for all functions
- **Docstrings**: Google style
- **Tests**: pytest with > 80% coverage

---

## ğŸ“š Learning Resources

### Anti-Cheat Systems
- [Riot Vanguard Deep Dive](https://technology.riotgames.com/news/riots-approach-anti-cheat)
- [Valve Anti-Cheat (VAC) Analysis](https://secret.club/2021/04/20/source-engine-bunnyhop-bans.html)
- [GDC Talk: Detecting Cheaters in Multiplayer Games](https://www.gdcvault.com/play/1025188/)

### Machine Learning for Security
- [Adversarial ML Threat Matrix](https://github.com/mitre/advmlthreatmatrix)
- [Anomaly Detection with Isolation Forests](https://cs.nju.edu.cn/zhouzh/zhouzh.files/publication/icdm08b.pdf)

### Feature Engineering
- [Physics-Based Features for Botting Detection](https://arxiv.org/abs/2003.12715)
- [Statistical Methods for Game Behavior Analysis](https://ieeexplore.ieee.org/document/8490418)

---

## ğŸ› Troubleshooting

### Common Issues

**Issue**: Kafka fails to start
```bash
# Solution: Increase Docker memory allocation
# Docker Desktop â†’ Settings â†’ Resources â†’ Memory: 8GB
```

**Issue**: Models not loading
```bash
# Solution: Train models first
python scripts/train_models.py
```

**Issue**: High false positive rate
```bash
# Solution: Calibrate thresholds
python src/training/calibrate_thresholds.py --target-fpr 0.001
```

**Issue**: Telemetry API 503 errors
```bash
# Solution: Scale up collectors
docker-compose up -d --scale collector=3
```

---

## ğŸ“ Project Roadmap

### Phase 1: Foundation (Current)
- âœ… Rule-based detection
- âœ… Anomaly detection (Isolation Forest)
- âœ… Basic feature engineering
- âœ… API ingestion

### Phase 2: Enhancement (Next)
- â³ LSTM temporal modeling
- â³ Autoencoder anomaly detection
- â³ Pseudo-labeling pipeline
- â³ Review queue UI

### Phase 3: Advanced (Future)
- ğŸ“… Transformer-based sequence modeling
- ğŸ“… Federated learning (privacy-preserving)
- ğŸ“… Real-time inference (< 10ms)
- ğŸ“… Mobile game support

---

## ğŸ“„ License

MIT License - See [LICENSE](LICENSE) file for details

---

## ğŸ™ Acknowledgments

- **Riot Games** for Vanguard research papers
- **scikit-learn** community for ML tools
- **FastAPI** team for excellent framework
- **Isolation Forest paper** (Liu et al., 2008)

---

## ğŸ“§ Contact

- **Project Maintainer**: Navaraja Mannepalli 
- **Email**: mannepallinavaraja@gmail.com
- **LinkedIn**: [LinkedIn](https://www.linkedin.com/in/navaraja-mannepalli/)
- **Portfolio**: [Portfolio Site](https://personal-portfolio-zeta-sepia-50.vercel.app/)

---

## â­ If This Project Helps You

If you found this useful for learning about production ML systems:
- Star the repository â­
- Share it with others learning ML engineering
- Use it as inspiration for your portfolio

**Note**: This is an educational project demonstrating production-grade architecture. For actual game deployments, consult with legal/compliance teams about player privacy regulations.

---

**Built with â¤ï¸ to demonstrate hybrid ML/DL systems for game integrity**
